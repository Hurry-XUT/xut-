2025年2月20日8:30 ——2025年2月28日21:09:17  邓淏云
目前进度：
1.已完成对静态网页部分的html提取
2.selenium让我抓取到更多内容，但是还是缺少超链接和“折叠起来的图片”，甚至超链接跳转之后的网页还有图片
3.通过edge浏览器右键检查功能，定位到翻页按钮，实现翻页
4.在检查页面中，监控网络日志。我清除了网络日志，再次在网页中试图点开被折叠起来的图片，网络日志（XHR）中，返回了新的结果
我认为，这可能是我下一步突破的关键
困难：1.我试图复刻该方法,通过点击网页超链接在网络日志中获得新的东西，可惜失败了——什么都没更新，看来这部分是不需要向服务器获取请求的。
这个url应该就在这里。可是源代码我没有发现<a>这个关键字。
2.解构进度4新获取的新结果。
新进展：selenium我可以直接模拟点击操作，这可以绕过抓取超链接，如果路径有规律的话element = driver.find_element(By.XPATH, "xpath_of_the_link_or_button")
获取超链接，难度比我想象大。它们可能已经预加载了，对网站中某些数值建立一些哈希表做变化？然后用某些触发器？
网页是通过刷新网页，更新内容，所有也不太像定时更新进超链接。
所以超链接，应该就在我本地缓存中的！我不需要捕获请求。监控本地缓存？找特定的url ???做不到，ai给的方案暂时看不懂。
考虑模拟点击操作吧，毕竟是一个比较规矩的表格，路径格式应该是有规律可循的。如果有规律，那么就能套循环生成队列
2025年3月1日16:19:35   邓淏云
我不再执着找超链接，真找不到
可喜可贺，每个公司的xpath路径是有规律的。
跳转之后的“营业执照”也是可以直接找到的。现在就差“联系公函了”
如果可以顺利获取“联系公函”，技术瓶颈就没有了。
捕获到“联系公函”的url。但是，，但是，，各个url规律不明显。而且，有的企业行不提供图片，它们是pdf,这是直接跳转的新网页。这个部分估计需要许多的
if else……
好，现在来梳理逻辑。
网页的html已经在我本地了
我可以直接建立文件夹框架，然后再网页中使用规律性的xpath路径按钮跳转网页，获取新的html再获取“营业执照”，存入文件夹框架。
退回网页，xpath后进行图片 or pdf判断。
if 图片
   得到url,直接存
else if PDF
    跳转网页
    （暂时直接存pdf）
else null
    这个无所谓嘛，最后的文件夹人工排查
好像没毛病。
难点在于，，点出新网页，如何让代码跟过去？再跳回来？（这部分应该不难）图片的url,如何存下来？我现在只在浏览器开发工具中监控到。
2025年3月1日22:49:05 邓淏云
决定清一色模拟点击。
遇到了许多问题，尝试系统学学selenium。确实方便看我定位网页元素。
但是，关键性的跳转网页的元素居然不能交互，这会卡我进度，我网页跳转测试无法进行。
element not interactable，如何是好呢？stackoverflow，csdn没找有参考的……很麻烦这算是反爬手段吧？
2025年3月2日09:20:29   邓淏云
关键性的跳转网页的元素居然不能交互,排查了诸多问题，但是直接用JS解决
 突破！！大突破！！使用JavaScript直接调用click（）成功点击！！目标虽然在::before ::after之间，但不是伪元素
deepseek NB! 感谢前辈！
现在技术瓶颈还剩，，，对html解析，然后是正则表达式？正则表达式，学得不太好，不过应该也不算太难
2025年3月2日14:42:58   邓淏云
已经实现网页跳转并且保存
正则表达式太麻烦了，BeautifulSoup稍微学一下
已经成功完成文件夹框架部分，需要存入“营业执照”，“联系公函”，招聘简章内容写入
2025年3月2日17:04:48   邓淏云
可以爬取到主网页的每一个公司背后的html,不出意外营业执照也在里面
1.如何爬取三页呢？
2.如何存入指定路径呢？
3.如何获取联系公函呢？
2025年3月2日18:40:51   邓淏云
已经爬取所有公司的html
如何存入指定路径？
2025年3月2日20:49:07   邓淏云
剩下的技术瓶颈还剩俩
复杂的招聘简章解析
有的公司在这个栏目放文本，并且是多段落，多字体大小，于是存在非常多，且数量不固定的<p>标签
有的公司放图片
有的公司俩都放，且数量不固定
有的公司不放
情况比较复杂。这甚至没考虑内容是否违规。

“执行公函”在网页藏在比较“炫酷”的位置，这部分不好获取。
同样情况复杂。有pdf,有图片，pdf里面还有俩情况pdf1,pdf2
可以点击“下载”而非“预览”弹出一个小窗口再点下载可以获得压缩包
如何控制到这个弹窗？

邓淏云啊邓淏云，招聘简章部分应该是可以解决的。这种难题应该是爬虫领域比较常见的类型。


2025年3月3日23:16:52    邓淏云
发现了一个bug
不同公司网页中，关于招聘简章的元素，居然会出现路径不一样！
真该死啊！比如！！！
//*[@id="pane-apply"]/div/div[1]/div[11]/div/div[2]/div
//*[@id="pane-apply"]/div/div[1]/div[12]/div/div[2]/div
为什么会不一样！
畜生！
这也许算小bug,偶尔少一两个公司，，问题不大？
2025年3月3日23:34:33   邓淏云
不同公司网页中，关于招聘简章的元素，居然会出现路径不一样！（已解决，后续可能有类似的问题，这里做个逻辑处理）如下
   # 定位目标 div
    target_div = soup.select_one(
        "#pane-apply > div > div:nth-of-type(1) > div:nth-of-type(12) > div > div:nth-of-type(2) > div")
    if not target_div:
        target_div = soup.select_one(
            "#pane-apply > div > div:nth-of-type(1) > div:nth-of-type(11) > div > div:nth-of-type(2) > div")
    if target_div or target_div :
但是问题依然没解决。26个html只保存到了24个，这个bug在哪？这才是让我少公司的元凶！
2025年3月4日14:54:41     邓淏云
发现问题了
居然是网络
爬取网页html的时候，某些公司网页还没来的及加载完成，比如某些图片比较高清，加载慢
在没有加载完全的时候爬取html，html会缺失我需要的元素！
该死的校园网，你就不能稳定且快速吗。你让高贵的西理学子浪费了多少时间！
应该也不怪校园网……是我自己忽略了这个简单的问题……
2025年3月5日12:07:50     邓淏云
难点：获取“联系公函”
1.联系公函通过“预览”多次折叠，考虑的网页的实时渲染，xpath可能定位不到。
而且，html没有这个图片的链接。这个图片需要请求的。
2.联系公函，如果通过“下载”，会弹出小窗，不确定之前的句柄操作能否应用到这个小窗。
而且，是小窗通过浏览器下载。
而且是个压缩包。
3.工作目标是保存为图片，可惜获取的相当部分为PDF,对于自动截图……难办
如果最后应用为人工截图，需要能筛选，并标记目标文件夹的程序。
两个路径：“预览”突破or"下载”突破
尝试下载，我希望能找到某个向服务器请求的接口。
点击下载后，小窗再点击下载，浏览器“网络选项卡”找到了一个神秘的东西，{"code":1,"msg":"","data":"https://o.bysjy.com.cn/school/yxqqnn2600000004/企业-西安泽达航空制造有限责任公司-回执材料-2025-03-05 12：17：17.zip.gz"}
里面有链接！
2025年3月6日21:15:10    邓淏云
难
2025年3月6日22:54:43    邓淏云
成功通过半自动化得到联系公函的压缩包，但是它在特定路径
//*[@id="companyListStyle"]/div[1]/div[3]/table/tbody/tr[1]/td[6]/div/div/div[1]/span(第一个公司的下载)
//*[@id="companyListStyle"]/div[1]/div[3]/table/tbody/tr[2]/td[6]/div/div/div[1]/span(第二个公司的下载)
//*[@id="exporyDialog"]/div/div/div[2]/div/div[4]/p[2]/a
//*[@id="exporyDialog"]/div/div/div[2]/div/div[4]/p[2]/a(观察到弹窗后的“下载”xpath路径是一样的)
打开主网页
for i in range()
    点击“下载”
    爬取html
    点击“关闭”
for i in range()
    解析html
    得到url
    下载url
    解压到目标文件夹
假设以及得到所有需要的html
for 循环
    解析营业执照html
    得到营业执照
    建立文件夹i
    解析招聘简章html
    存入word
    保存进文件夹i
    解析联系公函html
    解压and重命名
    存入文件夹i
循环结束
某某日期双选基础版 就完成啦！
然后开始审核
人工记录不合格公司
删除不合格公司文件夹
标注.py
筛选出文件夹中有PDF的文件夹
人工替换！！
邓淏云的作品就完成啦！！！
哟西，很好，干得漂亮。我很期待。截止2025年3月6日23:39:01

2025年3月7日18:43:19   邓淏云
勉强能爬取联系公函的html，但是不稳定？尤其是模拟点击“下载”非常不稳定
如果在测试的时候点击过“下载”，第二次模拟点击就会失败。这可能是网站的保护手段？
2025年3月7日19:22:32   邓淏云（已解决）
电击“下载”之后html会改变，同时考虑两个路径模拟点击就行了
又到了解析html环节
2025年3月7日19:48:02   邓淏云
拿到压缩包了
2025年3月7日22:17:11   邓淏云
项目勉强成功了，可是预计30个企业，只拿到了27个，问题并不是出在联系公函上，在哪里呢？
只是小错误，最后忘改循环条件了，代码逻辑没问题。无论问题再小，都会导致整个目标实现不了。
成功了！
感谢就业办提供的环境，我可以有一个宽敞的地方安静代码，甚至还有暖气，水，充电。
感谢教学免费的网络，我已经差不多半个月没有交网费了，天天来这蹭校园网。网费虽然不算特别贵，但是免费的用得我很开心！

后续优化方向：
爬取部分，三合一，每爬一个项目都需要启动浏览器。很麻烦！
招聘简章记录不理想！————————————————————————————————2025年3月8日00:03:10 邓淏云

2025年3月8日19:43:34  邓淏云
尝试优化对招聘简章的解析，主要是表格和图文混合



